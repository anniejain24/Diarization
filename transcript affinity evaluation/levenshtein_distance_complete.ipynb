{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.9\n",
      "0.9\n",
      "0.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m reconstruct_transcript(diarized_transcript, \u001b[38;5;28mid\u001b[39m)\n\u001b[1;32m     62\u001b[0m reconstructed\n\u001b[0;32m---> 63\u001b[0m \u001b[43mnormalized_levenshtein\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstructed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m normalized_levenshtein\u001b[38;5;241m.\u001b[39msimilarity(transcript, reconstructed)\n\u001b[1;32m     65\u001b[0m normalized_levenshtein\u001b[38;5;241m.\u001b[39mdistance(transcript, transcript)\n",
      "File \u001b[0;32m~/.conda/envs/pf/lib/python3.9/site-packages/strsimpy/normalized_levenshtein.py:41\u001b[0m, in \u001b[0;36mNormalizedLevenshtein.distance\u001b[0;34m(self, s0, s1)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevenshtein\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m m_len\n",
      "File \u001b[0;32m~/.conda/envs/pf/lib/python3.9/site-packages/strsimpy/levenshtein.py:50\u001b[0m, in \u001b[0;36mLevenshtein.distance\u001b[0;34m(self, s0, s1)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s0[i] \u001b[38;5;241m==\u001b[39m s1[j]:\n\u001b[1;32m     49\u001b[0m             cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m         v1[j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     v0, v1 \u001b[38;5;241m=\u001b[39m v1, v0\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v0[\u001b[38;5;28mlen\u001b[39m(s1)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n",
    "\n",
    "normalized_levenshtein = NormalizedLevenshtein()\n",
    "print(normalized_levenshtein.distance('My string', 'My $string'))\n",
    "print(normalized_levenshtein.distance('My string', 'My $string'))\n",
    "print(normalized_levenshtein.distance('My string', 'My $string'))\n",
    "\n",
    "print(normalized_levenshtein.similarity('My string', 'My $string'))\n",
    "print(normalized_levenshtein.similarity('My string', 'My $string'))\n",
    "print(normalized_levenshtein.similarity('My string', 'My $string'))\n",
    "# get original transcript\n",
    "\n",
    "transcript_id = '10_0991_331330'\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "def read_transcript_from_id(transcript_id):\n",
    "\n",
    "    path_to_data_folder = '/archive/shared/sim_center/shared/ameer/'\n",
    "    # lookinto this dictionary to find the path\n",
    "    # can also manually create the path and it would be faster but not by much\n",
    "    merged_lookup = pd.read_csv(path_to_data_folder + 'grade_lookupv5.csv')\n",
    "    transcript = ''\n",
    "\n",
    "    path = merged_lookup[merged_lookup.id == transcript_id].path.iloc[0]\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        if line != '\\n':\n",
    "            tok_line = line.split(' ')\n",
    "            for i in range(len(tok_line)):\n",
    "                transcript += ' ' + tok_line[i]\n",
    "\n",
    "\n",
    "    return transcript\n",
    "    \n",
    "transcript = read_transcript_from_id(transcript_id)\n",
    "transcript\n",
    "diarized_transcript = '/archive/shared/sim_center/shared/annie/GPT4 3-chunk/'\n",
    "id = '10_0991_331330'\n",
    "def reconstruct_transcript(path, id): \n",
    "    transcript = ''\n",
    "    path = path + id + '.txt'\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines[1:]:\n",
    "        if line != '\\n':\n",
    "            tok_line = line.split(' ')\n",
    "            for i in range(1,len(tok_line)):\n",
    "                transcript += ' ' + tok_line[i]\n",
    "    \n",
    "    resid_lines = transcript.split('\\n')\n",
    "    transcript = ''\n",
    "    for line in resid_lines:\n",
    "        transcript += line\n",
    "\n",
    "    return transcript\n",
    "\n",
    "reconstructed = reconstruct_transcript(diarized_transcript, id)\n",
    "reconstructed\n",
    "normalized_levenshtein.distance(transcript, reconstructed)\n",
    "normalized_levenshtein.similarity(transcript, reconstructed)\n",
    "normalized_levenshtein.distance(transcript, transcript)\n",
    "#Run for all IDs\n",
    "# IDs for the test/sample transcripts\n",
    "\n",
    "ids = ['01_0542_298135',\n",
    "'02_0036_174595',\n",
    "'03_0028_174553',\n",
    "'04_0043_174686',\n",
    "'05_0033_174804',\n",
    "'06_0079_175106',\n",
    "'07_0068_174641',\n",
    "'08_0029_174576',\n",
    "'09_0029_174582',\n",
    "'10_0991_331330']\n",
    "\n",
    "gpt35_path = '/archive/shared/sim_center/shared/annie/GPT3.5 complete/'\n",
    "mixtral_path = '/archive/shared/sim_center/shared/annie/mixtral/'\n",
    "gpt4_path = '/archive/shared/sim_center/shared/annie/GPT4 complete (json split)/'\n",
    "gpt4_3chunk = '/archive/shared/sim_center/shared/annie/GPT4 3-chunk/'\n",
    "gpt4_6chunk = '/archive/shared/sim_center/shared/annie/GPT4 6-chunk/'\n",
    "gpt4_9chunk = '/archive/shared/sim_center/shared/annie/GPT4 9-chunk/'\n",
    "\n",
    "gpt35_init = []\n",
    "mixtral_init = []\n",
    "gpt4_init = []\n",
    "gpt4_3chunk = []\n",
    "gpt4_6chunk = []\n",
    "gpt4_9chunk = []\n",
    "def eval_transcript(ids, path):\n",
    "    scores = {}\n",
    "    for id in ids:\n",
    "        print(id)\n",
    "        transcript = read_transcript_from_id(id)\n",
    "        reconstructed_transcript = reconstruct_transcript(path, id)\n",
    "        distance = normalized_levenshtein.distance(transcript, reconstructed_transcript)\n",
    "        similarity = normalized_levenshtein.similarity(transcript, reconstructed_transcript)\n",
    "        scores[id] = [distance, similarity]\n",
    "    return scores\n",
    "    \n",
    "gpt4_init = eval_transcript(ids, gpt4_path)\n",
    "gpt4_init\n",
    "gpt4_df = pd.DataFrame(gpt4_init)\n",
    "gpt4_df.to_csv(\"gpt4_init.csv\")\n",
    "mixtral_init = eval_transcript(ids, mixtral_path)\n",
    "pd.DataFrame(mixtral_init).to_csv(\"mixtral_init.csv\")\n",
    "gpt35_init = eval_transcript(ids, gpt35_path)\n",
    "pd.DataFrame(gpt35_init).to_csv(\"gpt35_init.csv\")\n",
    "gpt4_dists = []\n",
    "gpt35_dists = []\n",
    "mixtral_dists = []\n",
    "gpt4_sim = []\n",
    "gpt35_sim = []\n",
    "mixtral_sim = []\n",
    "\n",
    "for id in ids:\n",
    "    gpt4_sim.append(gpt4_init[id][1])\n",
    "    gpt4_dists.append(gpt4_init[id][0])\n",
    "    gpt35_sim.append(gpt35_init[id][1])\n",
    "    gpt35_dists.append(gpt35_init[id][0])\n",
    "    mixtral_sim.append(mixtral_init[id][1])\n",
    "    mixtral_dists.append(mixtral_init[id][0])\n",
    "\n",
    "gpt4_sim\n",
    "columns = ['COSCE ID', 'gpt4 sim', 'gpt4 dist', 'gpt35 sim', 'gpt35 dist', 'mixtral sim', 'mixtral dist']\n",
    "all_df = pd.DataFrame(zip(ids, gpt4_sim, gpt4_dists, gpt35_sim, gpt35_dists, mixtral_sim, mixtral_dists), columns=columns)\n",
    "all_df\n",
    "all_df.to_csv(\"levenshtein_gpt4_35_mixtral.csv\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "avg_dists = [np.mean(gpt4_dists), np.mean(gpt35_dists), np.mean(mixtral_dists)]\n",
    "avg_sim = [np.mean(gpt4_sim), np.mean(gpt35_sim), np.mean(mixtral_sim)]\n",
    "models = ['gpt4', 'gpt35', 'mixtral']\n",
    "plt.bar(models, avg_dists)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"normalized levenshtein distance\")\n",
    "plt.show()\n",
    "plt.bar(models, avg_sim)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"normalized levenshtein similarity\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
